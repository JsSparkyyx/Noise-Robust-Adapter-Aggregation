{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from peft import PeftModel\n",
    "from datasets import DatasetDict, load_dataset\n",
    "from utils import set_seed, k_split\n",
    "from tqdm import trange\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'sst2'\n",
    "data_name = 'glue' if task in ['mnli','qnli','sst2','qqp'] else 'bigbench'\n",
    "seed = 42\n",
    "num_clients = 10\n",
    "num_error_clients = 3\n",
    "number = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab2f406735441e0b4f5ea40c9a881d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\NLP\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Mtrx233\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54adf4d258e94d68a9bbda6448bba8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99b7ff5cbb84d57a4851c3d48369cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc51d4e28174e4394509faa9974e29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4a2b8b45ff4dc182d60d4f3ef7cc49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994ca306888e46e9b8c21e11c0d67476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628cf6f1f22641a1801aa12f6618a542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.15M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3205fbd7e75485f94dc8f07cd315cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/148k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818b5864f8904edeb55c178b7c41f932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/72.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4405bef189fc4e2a906e7a93c9212023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa99da5645a4b11bbc371846c9d402d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e169fe6e2a4769967389a3090faefd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6705221f514c8daee698d10bd3109e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating valid split:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name_or_path = 'google/flan-t5-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "set_seed(seed)\n",
    "if data_name == 'bigbench':\n",
    "    dataset = load_dataset(\"tasksource/bigbench\", task).shuffle(seed=seed)\n",
    "    dataset = dataset.rename_columns({'inputs':'source','targets':'target'})\n",
    "else:\n",
    "    dataset = load_dataset(\"JsSparkYyx/NLP524\", task).shuffle(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = k_split(num_clients,num_error_clients,dataset['train'])\n",
    "if data_name == 'glue':\n",
    "    valid_ds = k_split(num_clients,num_error_clients,dataset['valid'])\n",
    "else:\n",
    "    valid_ds = k_split(num_clients,num_error_clients,dataset['validation'])\n",
    "dataset = DatasetDict({'train':train_ds[number],'valid':valid_ds[number]})\n",
    "def tokenize_function(examples):\n",
    "    # max_length=None => use the model max length (it's actually the default)\n",
    "    model_inputs = tokenizer(examples['source'], truncation=True, max_length=None,padding=True,return_tensors='pt')\n",
    "    if data_name == 'glue':\n",
    "        model_inputs['labels'] = tokenizer(examples['target'], truncation=True, max_length=None,padding=True,return_tensors='pt')[\"input_ids\"]\n",
    "    else:\n",
    "        model_inputs['labels'] = tokenizer([_[0] for _ in examples['target']], truncation=True, max_length=None,padding=True,return_tensors='pt')[\"input_ids\"]\n",
    "    return model_inputs\n",
    "ds = (train_ds, valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive_data(ds,number):\n",
    "    (train_ds, valid_ds) = ds\n",
    "    return DatasetDict({'train':train_ds[number],'valid':valid_ds[number]})\n",
    "\n",
    "def accuracy_score(outputs, ground_truths):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for output, truth in zip(outputs, ground_truths):\n",
    "        if data_name == \"bigbench\":\n",
    "            truth = truth[0]\n",
    "        if output.strip().lower().replace(\".\", \"\") == truth.strip().lower().replace(\".\", \"\"):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = retrive_data(ds,number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(data, model, tokenizer, batch_size = 128):\n",
    "    example_predictions = []\n",
    "    eval_set = \"valid\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in trange(0, len(data[eval_set][\"source\"]), batch_size):\n",
    "            inputs = tokenizer(\n",
    "                    data[eval_set][\"source\"][i : i + batch_size],\n",
    "                    max_length=2048,\n",
    "                    return_tensors=\"pt\",\n",
    "                    padding=True,\n",
    "                ).to(device)\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"], max_new_tokens=256\n",
    "            )\n",
    "            outputs = tokenizer.batch_decode(\n",
    "                outputs.to(\"cpu\"), skip_special_tokens=True\n",
    "            )\n",
    "            example_predictions.extend(outputs)\n",
    "\n",
    "    task_perf = accuracy_score(example_predictions, data[eval_set][\"target\"])\n",
    "    return task_perf, example_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "# lora_model = PeftModel.from_pretrained(model_1,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "# model_2 = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "# error_model = PeftModel.from_pretrained(model_2,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-0')\n",
    "# task_perf, example_predictions = evaluation(data,lora_model,tokenizer, batch_size=8)\n",
    "# task_perf_error, example_predictions_error = evaluation(data,error_model,tokenizer, batch_size=8)\n",
    "# print(f\"ACC of error model: {task_perf_error}, ACC of lora model: {task_perf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf804d8317b401a8bada49c39313a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb91947061ed4060a8b76975c1b1cf2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ded30ee35994c1a8b1f50e193fb4955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b206f6477983475a8984b89eba3cd17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/497 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8b5508077e4533a8c3c7831e90586f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f762f2e36fc3485584c8577d50965696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/497 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2840b7ad24443d9f2647240143b65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daec3c47c61a4dee8fdce44b1696ae19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/497 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec55ff4397d463cb0142c9237c24f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de59a960b85a45b28b3ea64367257ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/497 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46f782b924842d8afe3cbe9bfe88349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3dd6cec8574d2ea0cc7780b9dd56ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/497 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4530aafd7f944c89aa776f8b5b35274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d58c35afa648888bdb18692cfab829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/497 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3dd6a8f605c45ee86ffd32a66b20118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d72ac3ec3c4f0db5c53a8fdadf0618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/497 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7562b372ce5c4fc393a9c6c93044b1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0be6f35742e489896d19634ef44d47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/497 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271da919e8214d7f965cdf73efff44c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db33d98c8a714b6bb42536f4e9c55426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/497 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb94297081348a898cf77f8ae18abe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e4b0e5937b40ecb011cf84adf78822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/497 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f36f01784e44c94b60d3140085e32c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import get_peft_model_state_dict\n",
    "lora_adaptors = []\n",
    "for i in range(num_clients):\n",
    "    base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "    lora_model = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{i}')\n",
    "    lora_adaptors.append(get_peft_model_state_dict(lora_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f98c482537f4b35b8e3a1f9d105c310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Begin to perform gradient-free optimization ...\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.1059434175491333\n",
      "39 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.0731708550453186\n",
      "38 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.07984742403030395\n",
      "37 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.08163163542747498\n",
      "36 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.060356758832931526\n",
      "35 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.05388559818267822\n",
      "34 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.034430744349956514\n",
      "33 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 2.081433868408203\n",
      "32 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 1.981958770751953\n",
      "31 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 2.0273384094238285\n",
      "30 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 1.8729873657226561\n",
      "29 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.06150785369219285\n",
      "28 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.05159514418513527\n",
      "27 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.04039195669433153\n",
      "26 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.0337758931012423\n",
      "25 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.0344647469126142\n",
      "24 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.04413795308838736\n",
      "23 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03667223633384947\n",
      "22 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.036184910110370574\n",
      "21 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.1254587190855102\n",
      "20 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.046664874843256425\n",
      "19 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.13358640944135725\n",
      "18 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.041967227741303355\n",
      "17 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.22369583324077588\n",
      "16 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.05009337496574723\n",
      "15 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 1.1509462379407203\n",
      "14 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.035305840749962285\n",
      "13 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.04612151288566899\n",
      "12 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.038298365892221735\n",
      "11 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.033727670963039295\n",
      "10 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03622037478479248\n",
      "9 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03392182488350351\n",
      "8 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03729964017029988\n",
      "7 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03410549786587162\n",
      "6 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03851996546546801\n",
      "5 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.036765206349835065\n",
      "4 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03385737172000403\n",
      "3 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.037872894060002764\n",
      "2 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03415770605610786\n",
      "1 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.034657252342772636\n",
      "0 remaining budget and 0 running jobs\n"
     ]
    }
   ],
   "source": [
    "from algorithm import lorahub_aggregation\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "base_lora = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "weights, lorahub_model = lorahub_aggregation(base_lora, lora_adaptors, data[\"valid\"], tokenizer, batch_size = 5, sample_size = 5, seed = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                      | 0/11 [00:00<?, ?it/s]E:\\Anaconda\\envs\\NLP\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2411: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.64it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.58it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC of client's model: 94.25287356321839, ACC of average aggregated model: 90.80459770114942, ACC of lorahub model: 94.25287356321839, ACC of no noise model: 91.95402298850574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from algorithm import average_aggregation\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "base_lora = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "avg_model = average_aggregation(base_lora,lora_adaptors)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "base_lora = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "no_noise_model = average_aggregation(base_lora,lora_adaptors[3:])\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "client_model = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "task_perf_avg, example_predictions = evaluation(data,avg_model,tokenizer, batch_size=8)\n",
    "task_perf_client, example_predictions_error = evaluation(data,client_model,tokenizer, batch_size=8)\n",
    "task_perf_lorahub, example_predictions_error = evaluation(data,lorahub_model,tokenizer, batch_size=8)\n",
    "task_perf_no_noise, example_predictions_error = evaluation(data,no_noise_model,tokenizer, batch_size=8)\n",
    "print(f\"ACC of client's model: {task_perf_client}, ACC of average aggregated model: {task_perf_avg}, ACC of lorahub model: {task_perf_lorahub}, ACC of no noise model: {task_perf_no_noise}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.95099211e-01 -2.94318024e-04 -3.62541694e-04  5.00564874e-01\n",
      "  5.00285263e-01  5.00857613e-01  2.40444428e-01 -8.58513709e-02\n",
      " -8.53954469e-02 -8.10476687e-02]\n",
      "91.95402298850574\n"
     ]
    }
   ],
   "source": [
    "print(weights)\n",
    "print(task_perf_no_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "def combination(n, k):\n",
    "    # generate C_n_k, n is the total number of adapters, k is the number of error clients\n",
    "    elements = range(n)\n",
    "    combinations_n_k = list(combinations(elements, k))\n",
    "    return combinations_n_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(base_model, lora_adaptors, num_error_client):\n",
    "    # \"adapters\" should be a list of adapters\n",
    "    total = len(lora_adaptors)\n",
    "    combination_n_k = combination(total, num_error_client)\n",
    "\n",
    "    aggregated = []\n",
    "    for outside in combination_n_k:\n",
    "        inside = []\n",
    "        for i, lora_adaptor in enumerate(lora_adaptors):\n",
    "            if i not in outside:\n",
    "                # aggregate\n",
    "                inside.append(lora_adaptor)\n",
    "        weights = average_aggregation(base_model, inside)\n",
    "        aggregated.append(weights)\n",
    "    performance = 0\n",
    "    best = -1\n",
    "    for i in range(len(aggregated)):\n",
    "        model = aggregated[i]\n",
    "        task_perf_cross_val, example_predictions_error = evaluation(data,model,tokenizer, batch_size=8)\n",
    "        if performance < task_perf_cross_val:\n",
    "            performance = task_perf_cross_val\n",
    "            best = i\n",
    "    return aggregated[i], performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.58it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.35it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.39it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.46it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.57it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.57it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.57it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.46it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.46it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.57it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.57it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.41it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.95402298850574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cv_weights, perf = cross_validation(base_lora, lora_adaptors, 3)\n",
    "print(perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

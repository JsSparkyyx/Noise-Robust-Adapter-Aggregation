{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from peft import PeftModel\n",
    "from datasets import DatasetDict, load_dataset\n",
    "from utils import set_seed, k_split\n",
    "from tqdm import trange\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'sst2'\n",
    "data_name = 'glue' if task in ['mnli','qnli','sst2','qqp'] else 'bigbench'\n",
    "seed = 42\n",
    "num_clients = 10\n",
    "num_error_clients = 3\n",
    "number = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'google/flan-t5-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "set_seed(seed)\n",
    "if data_name == 'bigbench':\n",
    "    dataset = load_dataset(\"tasksource/bigbench\", task).shuffle(seed=seed)\n",
    "    dataset = dataset.rename_columns({'inputs':'source','targets':'target'})\n",
    "else:\n",
    "    dataset = load_dataset(\"JsSparkYyx/NLP524\", task).shuffle(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = k_split(num_clients,num_error_clients,dataset['train'])\n",
    "if data_name == 'glue':\n",
    "    valid_ds = k_split(num_clients,num_error_clients,dataset['valid'])\n",
    "else:\n",
    "    valid_ds = k_split(num_clients,num_error_clients,dataset['validation'])\n",
    "dataset = DatasetDict({'train':train_ds[number],'valid':valid_ds[number]})\n",
    "def tokenize_function(examples):\n",
    "    # max_length=None => use the model max length (it's actually the default)\n",
    "    model_inputs = tokenizer(examples['source'], truncation=True, max_length=None,padding=True,return_tensors='pt')\n",
    "    if data_name == 'glue':\n",
    "        model_inputs['labels'] = tokenizer(examples['target'], truncation=True, max_length=None,padding=True,return_tensors='pt')[\"input_ids\"]\n",
    "    else:\n",
    "        model_inputs['labels'] = tokenizer([_[0] for _ in examples['target']], truncation=True, max_length=None,padding=True,return_tensors='pt')[\"input_ids\"]\n",
    "    return model_inputs\n",
    "ds = (train_ds, valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive_data(ds,number):\n",
    "    (train_ds, valid_ds) = ds\n",
    "    return DatasetDict({'train':train_ds[number],'valid':valid_ds[number]})\n",
    "\n",
    "def accuracy_score(outputs, ground_truths):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for output, truth in zip(outputs, ground_truths):\n",
    "        if data_name == \"bigbench\":\n",
    "            truth = truth[0]\n",
    "        if output.strip().lower().replace(\".\", \"\") == truth.strip().lower().replace(\".\", \"\"):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = retrive_data(ds,number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(data, model, tokenizer, batch_size = 128):\n",
    "    example_predictions = []\n",
    "    eval_set = \"valid\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in trange(0, len(data[eval_set][\"source\"]), batch_size):\n",
    "            inputs = tokenizer(\n",
    "                    data[eval_set][\"source\"][i : i + batch_size],\n",
    "                    max_length=2048,\n",
    "                    return_tensors=\"pt\",\n",
    "                    padding=True,\n",
    "                ).to(device)\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"], max_new_tokens=256\n",
    "            )\n",
    "            outputs = tokenizer.batch_decode(\n",
    "                outputs.to(\"cpu\"), skip_special_tokens=True\n",
    "            )\n",
    "            example_predictions.extend(outputs)\n",
    "\n",
    "    task_perf = accuracy_score(example_predictions, data[eval_set][\"target\"])\n",
    "    return task_perf, example_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "# lora_model = PeftModel.from_pretrained(model_1,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "# model_2 = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "# error_model = PeftModel.from_pretrained(model_2,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-0')\n",
    "# task_perf, example_predictions = evaluation(data,lora_model,tokenizer, batch_size=8)\n",
    "# task_perf_error, example_predictions_error = evaluation(data,error_model,tokenizer, batch_size=8)\n",
    "# print(f\"ACC of error model: {task_perf_error}, ACC of lora model: {task_perf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model_state_dict\n",
    "lora_adaptors = []\n",
    "for i in range(num_clients):\n",
    "    base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "    lora_model = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{i}')\n",
    "    lora_adaptors.append(get_peft_model_state_dict(lora_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9e10d7150245ebbe0bab55389fa4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Begin to perform gradient-free optimization ...\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.10594421625137329\n",
      "39 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.0731716775894165\n",
      "38 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.07984843134880067\n",
      "37 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.08163272023200989\n",
      "36 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.0603573489189148\n",
      "35 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.0538857501745224\n",
      "34 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03443073987960815\n",
      "33 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 2.081432723999024\n",
      "32 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 1.9819580078124999\n",
      "31 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 2.0273380279541016\n",
      "30 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 1.8729869842529296\n",
      "29 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.06150865620650218\n",
      "28 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.05159544858474218\n",
      "27 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.04039201927752932\n",
      "26 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03377589898167093\n",
      "25 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.034464757180292106\n",
      "24 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.044137905835792766\n",
      "23 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03667219596034111\n",
      "22 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03618485391568627\n",
      "21 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.12545895734358714\n",
      "20 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.046664918123749115\n",
      "19 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.13358790003742554\n",
      "18 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.04196723524166697\n",
      "17 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.223696452942233\n",
      "16 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.0500933525214562\n",
      "15 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 1.1509487070162883\n",
      "14 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.035305778311690836\n",
      "13 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.04612159161438475\n",
      "12 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03634894741594351\n",
      "11 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03372771409435979\n",
      "10 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.036203201572581\n",
      "9 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03374389061610403\n",
      "8 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.039515605798885745\n",
      "7 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.033778190223173375\n",
      "6 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03473482418666986\n",
      "5 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.04045362223552762\n",
      "4 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03859645453136984\n",
      "3 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.0341885835483421\n",
      "2 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.03435986134235444\n",
      "1 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "Updating fitness with value 0.034025242587252424\n",
      "0 remaining budget and 0 running jobs\n"
     ]
    }
   ],
   "source": [
    "from algorithm import lorahub_aggregation\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "base_lora = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "weights, lorahub_model = lorahub_aggregation(base_lora, lora_adaptors, data[\"valid\"], tokenizer, batch_size = 5, sample_size = 5, seed = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 26.80it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 15.01it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 28.21it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 28.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC of client's model: 94.25287356321839, ACC of average aggregated model: 90.80459770114942, ACC of lorahub model: 94.25287356321839, ACC of no noise model: 91.95402298850574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from algorithm import average_aggregation\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "base_lora = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "avg_model = average_aggregation(base_lora,lora_adaptors)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "base_lora = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "no_noise_model = average_aggregation(base_lora,lora_adaptors[3:])\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "client_model = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "task_perf_avg, example_predictions = evaluation(data,avg_model,tokenizer, batch_size=8)\n",
    "task_perf_client, example_predictions_error = evaluation(data,client_model,tokenizer, batch_size=8)\n",
    "task_perf_lorahub, example_predictions_error = evaluation(data,lorahub_model,tokenizer, batch_size=8)\n",
    "task_perf_no_noise, example_predictions_error = evaluation(data,no_noise_model,tokenizer, batch_size=8)\n",
    "print(f\"ACC of client's model: {task_perf_client}, ACC of average aggregated model: {task_perf_avg}, ACC of lorahub model: {task_perf_lorahub}, ACC of no noise model: {task_perf_no_noise}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.95099199e-01 -2.94326107e-04 -3.62552962e-04  5.00564884e-01\n",
      "  5.00285282e-01  5.00857620e-01  2.40444463e-01 -8.58513193e-02\n",
      " -8.53954377e-02 -8.10476350e-02]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

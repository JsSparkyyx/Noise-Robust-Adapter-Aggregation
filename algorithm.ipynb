{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from peft import PeftModel\n",
    "from datasets import DatasetDict, load_dataset\n",
    "from utils import set_seed, k_split\n",
    "from tqdm import trange\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'sst2'\n",
    "data_name = 'glue' if task in ['mnli','qnli','sst2','qqp'] else 'bigbench'\n",
    "seed = 42\n",
    "num_clients = 10\n",
    "num_error_clients = 3\n",
    "number = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'google/flan-t5-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "set_seed(seed)\n",
    "if data_name == 'bigbench':\n",
    "    dataset = load_dataset(\"tasksource/bigbench\", task).shuffle(seed=seed)\n",
    "    dataset = dataset.rename_columns({'inputs':'source','targets':'target'})\n",
    "else:\n",
    "    dataset = load_dataset(\"JsSparkYyx/NLP524\", task).shuffle(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5TokenizerFast(name_or_path='google/flan-t5-base', vocab_size=32100, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "def k_split_(num_clients,num_error_clients,dataset):\n",
    "    data = []\n",
    "    for i in range(num_clients):\n",
    "        subdata = dataset.shard(num_clients,i)\n",
    "        target = subdata['target']\n",
    "        source = subdata['source']\n",
    "        if i < num_error_clients:\n",
    "            random.shuffle(target)\n",
    "        subdata = Dataset.from_dict({'source':source, 'target':target})\n",
    "        data.append(subdata)\n",
    "    return data\n",
    "\n",
    "train_ds = k_split_(num_clients,num_error_clients,dataset['train'])\n",
    "if data_name == 'glue':\n",
    "    valid_ds = k_split_(num_clients,num_error_clients,dataset['valid'])\n",
    "else:\n",
    "    valid_ds = k_split_(num_clients,num_error_clients,dataset['validation'])\n",
    "dataset = DatasetDict({'train':train_ds[number],'valid':valid_ds[number]})\n",
    "def tokenize_function(examples):\n",
    "    # max_length=None => use the model max length (it's actually the default)\n",
    "    model_inputs = tokenizer(examples['source'], truncation=True, max_length=None,padding=True,return_tensors='pt')\n",
    "    if data_name == 'glue':\n",
    "        model_inputs['labels'] = tokenizer(examples['target'], truncation=True, max_length=None,padding=True,return_tensors='pt')[\"input_ids\"]\n",
    "    else:\n",
    "        model_inputs['labels'] = tokenizer([_[0] for _ in examples['target']], truncation=True, max_length=None,padding=True,return_tensors='pt')[\"input_ids\"]\n",
    "    return model_inputs\n",
    "ds = (train_ds, valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive_data(ds,number):\n",
    "    (train_ds, valid_ds) = ds\n",
    "    return DatasetDict({'train':train_ds[number],'valid':valid_ds[number]})\n",
    "\n",
    "def accuracy_score(outputs, ground_truths):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for output, truth in zip(outputs, ground_truths):\n",
    "        if data_name == \"bigbench\":\n",
    "            truth = truth[0]\n",
    "        if output.strip().lower().replace(\".\", \"\") == truth.strip().lower().replace(\".\", \"\"):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = retrive_data(ds,number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(data, model, tokenizer, batch_size = 128):\n",
    "    example_predictions = []\n",
    "    eval_set = \"valid\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in trange(0, len(data[eval_set][\"source\"]), batch_size):\n",
    "            inputs = tokenizer(\n",
    "                    data[eval_set][\"source\"][i : i + batch_size],\n",
    "                    max_length=2048,\n",
    "                    return_tensors=\"pt\",\n",
    "                    padding=True,\n",
    "                ).to(device)\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"], max_new_tokens=256\n",
    "            )\n",
    "            outputs = tokenizer.batch_decode(\n",
    "                outputs.to(\"cpu\"), skip_special_tokens=True\n",
    "            )\n",
    "            example_predictions.extend(outputs)\n",
    "\n",
    "    task_perf = accuracy_score(example_predictions, data[eval_set][\"target\"])\n",
    "    return task_perf, example_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "# lora_model = PeftModel.from_pretrained(model_1,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "# model_2 = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "# error_model = PeftModel.from_pretrained(model_2,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-0')\n",
    "# task_perf, example_predictions = evaluation(data,lora_model,tokenizer, batch_size=8)\n",
    "# task_perf_error, example_predictions_error = evaluation(data,error_model,tokenizer, batch_size=8)\n",
    "# print(f\"ACC of error model: {task_perf_error}, ACC of lora model: {task_perf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model_state_dict\n",
    "lora_adaptors = []\n",
    "for i in range(num_clients):\n",
    "    base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "    lora_model = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{i}')\n",
    "    lora_adaptors.append(get_peft_model_state_dict(lora_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bdeaca96274ca0a519abb770fa6b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Begin to perform gradient-free optimization ...\n",
      "Launching 1 jobs with new suggestions\n",
      "0.0\n",
      "nan\n",
      "Updating fitness with value nan\n",
      "39 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\NLP\\lib\\site-packages\\nevergrad\\optimization\\base.py:146: LossTooLargeWarning: Clipping very high value nan in tell (rescale the cost function?).\n",
      "  warnings.warn(msg, e)\n",
      "E:\\Anaconda\\envs\\NLP\\lib\\site-packages\\nevergrad\\optimization\\base.py:146: LossTooLargeWarning: Clipping very high value 5e+20 in tell (rescale the cost function?).\n",
      "  warnings.warn(msg, e)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012500000000000002\n",
      "0.0\n",
      "Updating fitness with value 0.0744208550453186\n",
      "38 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.0025000000000000005\n",
      "0.0\n",
      "Updating fitness with value 0.08234742403030396\n",
      "37 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.0025000000000000005\n",
      "0.0\n",
      "Updating fitness with value 0.08413163542747498\n",
      "36 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.0025000000000000005\n",
      "0.0\n",
      "Updating fitness with value 0.06285675883293153\n",
      "35 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.00375\n",
      "0.0\n",
      "Updating fitness with value 0.057635598182678216\n",
      "34 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005000000000000001\n",
      "0.0\n",
      "Updating fitness with value 0.03943074434995651\n",
      "33 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.00625\n",
      "0.0\n",
      "Updating fitness with value 2.0876838684082033\n",
      "32 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.00625\n",
      "0.0\n",
      "Updating fitness with value 1.9882087707519531\n",
      "31 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.00625\n",
      "0.0\n",
      "Updating fitness with value 2.0335884094238286\n",
      "30 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.00625\n",
      "0.0\n",
      "Updating fitness with value 1.8792373657226562\n",
      "29 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.008749999999999999\n",
      "0.0\n",
      "Updating fitness with value 0.5123236083984375\n",
      "28 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005173818287520523\n",
      "0.0\n",
      "Updating fitness with value 0.05749841892267883\n",
      "27 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005078125\n",
      "0.0\n",
      "Updating fitness with value 0.04271461487985401\n",
      "26 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005229073750207385\n",
      "0.0\n",
      "Updating fitness with value 0.038346589412559286\n",
      "25 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005307198750207385\n",
      "0.0\n",
      "Updating fitness with value 0.03892658103134912\n",
      "24 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005424035324352308\n",
      "0.0\n",
      "Updating fitness with value 0.04808481517124629\n",
      "23 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005932187746546519\n",
      "0.0\n",
      "Updating fitness with value 0.1482989870045668\n",
      "22 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005128813041737118\n",
      "0.0\n",
      "Updating fitness with value 0.040670592125273825\n",
      "21 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.0059321962334743135\n",
      "0.0\n",
      "Updating fitness with value 0.14949090997714834\n",
      "20 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.003479704263950655\n",
      "0.0\n",
      "Updating fitness with value 0.04964066905018524\n",
      "19 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005955778818761922\n",
      "0.0\n",
      "Updating fitness with value 0.1810618128922396\n",
      "18 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.004807790247188314\n",
      "0.0\n",
      "Updating fitness with value 0.057894039202056935\n",
      "17 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005014886232746047\n",
      "0.0\n",
      "Updating fitness with value 0.0367561270068607\n",
      "16 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.00509061115214229\n",
      "0.0\n",
      "Updating fitness with value 0.08960013440028268\n",
      "15 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.004687544887378724\n",
      "0.0\n",
      "Updating fitness with value 0.052804040023091164\n",
      "14 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005017936609563189\n",
      "0.0\n",
      "Updating fitness with value 0.038635437066956574\n",
      "13 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.004022079316172805\n",
      "0.0\n",
      "Updating fitness with value 0.044465601512980714\n",
      "12 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005075665089023036\n",
      "0.0\n",
      "Updating fitness with value 0.034813431097913794\n",
      "11 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005304503805339435\n",
      "0.0\n",
      "Updating fitness with value 0.03454283290040735\n",
      "10 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005430596988817531\n",
      "0.0\n",
      "Updating fitness with value 0.03442681251346316\n",
      "9 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005891013789910878\n",
      "0.0\n",
      "Updating fitness with value 0.034755456537791725\n",
      "8 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005583950119341859\n",
      "0.0\n",
      "Updating fitness with value 0.03484268103296448\n",
      "7 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.00514631378351673\n",
      "0.0\n",
      "Updating fitness with value 0.05178312116893987\n",
      "6 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.004931886332380137\n",
      "0.0\n",
      "Updating fitness with value 0.037760753221647486\n",
      "5 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005332502283388217\n",
      "0.0\n",
      "Updating fitness with value 0.03384525326834406\n",
      "4 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005711505657494491\n",
      "0.0\n",
      "Updating fitness with value 0.21387966136539982\n",
      "3 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.0053325550296669235\n",
      "0.0\n",
      "Updating fitness with value 0.035540733582519635\n",
      "2 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.005276331429292889\n",
      "0.0\n",
      "Updating fitness with value 0.03546020544461769\n",
      "1 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "0.0054149570329700735\n",
      "0.0\n",
      "Updating fitness with value 0.03378509568568375\n",
      "0 remaining budget and 0 running jobs\n"
     ]
    }
   ],
   "source": [
    "from adalgorithm import lorahub_aggregation\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "base_lora = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "weights, lorahub_model = lorahub_aggregation(base_lora, lora_adaptors, data[\"valid\"], tokenizer, batch_size = 5, sample_size = 5, seed = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                 | 0/11 [00:00<?, ?it/s]E:\\Anaconda\\envs\\NLP\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2411: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC of client's model: 94.25287356321839, ACC of average aggregated model: 90.80459770114942, ACC of lorahub model: 95.40229885057471, ACC of no noise model: 91.95402298850574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from adalgorithm import average_aggregation\n",
    "from utils import evaluation\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "base_lora = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "avg_model = average_aggregation(base_lora,lora_adaptors)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "base_lora = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "no_noise_model = average_aggregation(base_lora,lora_adaptors[3:])\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "client_model = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "# task_perf_avg, example_predictions = evaluation(data,avg_model,tokenizer, task, batch_size=8)\n",
    "# task_perf_client, example_predictions_error = evaluation(data,client_model,tokenizer, task, batch_size=8)\n",
    "# task_perf_lorahub, example_predictions_error = evaluation(data,lorahub_model,tokenizer, task, batch_size=8)\n",
    "# task_perf_no_noise, example_predictions_error = evaluation(data,no_noise_model,tokenizer, task, batch_size=8)\n",
    "task_perf_avg, example_predictions = evaluation(data,avg_model,tokenizer, batch_size=8)\n",
    "task_perf_client, example_predictions_error = evaluation(data,client_model,tokenizer, batch_size=8)\n",
    "task_perf_lorahub, example_predictions_error = evaluation(data,lorahub_model,tokenizer, batch_size=8)\n",
    "task_perf_no_noise, example_predictions_error = evaluation(data,no_noise_model,tokenizer, batch_size=8)\n",
    "print(f\"ACC of client's model: {task_perf_client}, ACC of average aggregated model: {task_perf_avg}, ACC of lorahub model: {task_perf_lorahub}, ACC of no noise model: {task_perf_no_noise}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [1. 2. 3. 4. 5.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.zeros((5,5))\n",
    "a[1] = [1,2,3,4,5]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(type(task_perf_client))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        # 定义10个可学习的参数\n",
    "        self.weights = nn.Parameter(torch.rand(10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 将每个参数乘以输入矩阵的对应列，然后对列求和，得到10x1的向量\n",
    "        return torch.matmul(x, self.weights.view(-1, 1))\n",
    "\n",
    "model = Model()\n",
    "optimizer = optim.Adam([model.weights], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1547965237.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    task_perf =\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "training_steps = 200\n",
    "for i in tqdm(range(training_steps)):\n",
    "    optimizer.zero_grad()\n",
    "    aggregated_weights = model(weights)\n",
    "    ########\n",
    "    # 合并成一个lora\n",
    "    # loss = evaludation\n",
    "    weighted_model = weighted_aggregation(base_lora, lora_adaptors, aggregated_weights)\n",
    "    task_perf, exmaple_predictions_error = evaluation(data, weighted_model, tokenizer, task, batch_size=8)\n",
    "    task_perf = \n",
    "\n",
    "    ########\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        print(loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

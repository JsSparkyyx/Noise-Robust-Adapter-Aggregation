{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from peft import PeftModel\n",
    "from datasets import DatasetDict, load_dataset\n",
    "from utils import set_seed, k_split\n",
    "from tqdm import trange\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'sst2'\n",
    "data_name = 'glue' if task in ['mnli','qnli','sst2','qqp'] else 'bigbench'\n",
    "seed = 42\n",
    "num_clients = 10\n",
    "num_error_clients = 3\n",
    "number = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'google/flan-t5-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "set_seed(seed)\n",
    "if data_name == 'bigbench':\n",
    "    dataset = load_dataset(\"tasksource/bigbench\", task).shuffle(seed=seed)\n",
    "    dataset = dataset.rename_columns({'inputs':'source','targets':'target'})\n",
    "else:\n",
    "    dataset = load_dataset(\"JsSparkYyx/NLP524\", task).shuffle(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5TokenizerFast(name_or_path='google/flan-t5-base', vocab_size=32100, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "def k_split_(num_clients,num_error_clients,dataset):\n",
    "    data = []\n",
    "    for i in range(num_clients):\n",
    "        subdata = dataset.shard(num_clients,i)\n",
    "        target = subdata['target']\n",
    "        source = subdata['source']\n",
    "        if i < num_error_clients:\n",
    "            random.shuffle(target)\n",
    "        subdata = Dataset.from_dict({'source':source, 'target':target})\n",
    "        data.append(subdata)\n",
    "    return data\n",
    "\n",
    "train_ds = k_split_(num_clients,num_error_clients,dataset['train'])\n",
    "if data_name == 'glue':\n",
    "    valid_ds = k_split_(num_clients,num_error_clients,dataset['valid'])\n",
    "else:\n",
    "    valid_ds = k_split_(num_clients,num_error_clients,dataset['validation'])\n",
    "dataset = DatasetDict({'train':train_ds[number],'valid':valid_ds[number]})\n",
    "def tokenize_function(examples):\n",
    "    # max_length=None => use the model max length (it's actually the default)\n",
    "    model_inputs = tokenizer(examples['source'], truncation=True, max_length=None,padding=True,return_tensors='pt')\n",
    "    if data_name == 'glue':\n",
    "        model_inputs['labels'] = tokenizer(examples['target'], truncation=True, max_length=None,padding=True,return_tensors='pt')[\"input_ids\"]\n",
    "    else:\n",
    "        model_inputs['labels'] = tokenizer([_[0] for _ in examples['target']], truncation=True, max_length=None,padding=True,return_tensors='pt')[\"input_ids\"]\n",
    "    return model_inputs\n",
    "ds = (train_ds, valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive_data(ds,number):\n",
    "    (train_ds, valid_ds) = ds\n",
    "    return DatasetDict({'train':train_ds[number],'valid':valid_ds[number]})\n",
    "\n",
    "def accuracy_score(outputs, ground_truths):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for output, truth in zip(outputs, ground_truths):\n",
    "        if data_name == \"bigbench\":\n",
    "            truth = truth[0]\n",
    "        if output.strip().lower().replace(\".\", \"\") == truth.strip().lower().replace(\".\", \"\"):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = retrive_data(ds,number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(data, model, tokenizer, batch_size = 128):\n",
    "    example_predictions = []\n",
    "    eval_set = \"valid\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in trange(0, len(data[eval_set][\"source\"]), batch_size):\n",
    "            inputs = tokenizer(\n",
    "                    data[eval_set][\"source\"][i : i + batch_size],\n",
    "                    max_length=2048,\n",
    "                    return_tensors=\"pt\",\n",
    "                    padding=True,\n",
    "                ).to(device)\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"], max_new_tokens=256\n",
    "            )\n",
    "            outputs = tokenizer.batch_decode(\n",
    "                outputs.to(\"cpu\"), skip_special_tokens=True\n",
    "            )\n",
    "            example_predictions.extend(outputs)\n",
    "\n",
    "    task_perf = accuracy_score(example_predictions, data[eval_set][\"target\"])\n",
    "    return task_perf, example_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "# lora_model = PeftModel.from_pretrained(model_1,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "# model_2 = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "# error_model = PeftModel.from_pretrained(model_2,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-0')\n",
    "# task_perf, example_predictions = evaluation(data,lora_model,tokenizer, batch_size=8)\n",
    "# task_perf_error, example_predictions_error = evaluation(data,error_model,tokenizer, batch_size=8)\n",
    "# print(f\"ACC of error model: {task_perf_error}, ACC of lora model: {task_perf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model_state_dict\n",
    "lora_adaptors = []\n",
    "for i in range(num_clients):\n",
    "    base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "    lora_model = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{i}')\n",
    "    lora_adaptors.append(get_peft_model_state_dict(lora_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7ffaac2ba24702bb1251f1dc3596c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Begin to perform gradient-free optimization ...\n",
      "Launching 1 jobs with new suggestions\n",
      "2205.1943359375\n",
      "0.0\n",
      "Updating fitness with value 0.1059434175491333\n",
      "39 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "1122.6883544921875\n",
      "0.0\n",
      "Updating fitness with value 0.0731708550453186\n",
      "38 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "926.9755249023438\n",
      "0.0\n",
      "Updating fitness with value 0.07984742403030395\n",
      "37 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "355.3238525390625\n",
      "0.0\n",
      "Updating fitness with value 0.08163163542747498\n",
      "36 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "1439.52978515625\n",
      "0.0\n",
      "Updating fitness with value 0.060356758832931526\n",
      "35 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "1413.2535400390625\n",
      "0.0\n",
      "Updating fitness with value 0.05388559818267822\n",
      "34 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "1760.7037353515625\n",
      "0.0\n",
      "Updating fitness with value 0.034430744349956514\n",
      "33 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "230.5142822265625\n",
      "0.0\n",
      "Updating fitness with value 2.081433868408203\n",
      "32 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "380.4351806640625\n",
      "0.0\n",
      "Updating fitness with value 1.981958770751953\n",
      "31 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "420.3448181152344\n",
      "0.0\n",
      "Updating fitness with value 2.0273384094238285\n",
      "30 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "260.10504150390625\n",
      "0.0\n",
      "Updating fitness with value 1.8729873657226561\n",
      "29 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "2288.930908203125\n",
      "0.0\n",
      "Updating fitness with value 0.06150785369219285\n",
      "28 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "1038.7838134765625\n",
      "0.0\n",
      "Updating fitness with value 0.05159514418513527\n",
      "27 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "1212.458740234375\n",
      "0.0\n",
      "Updating fitness with value 0.04039195669433153\n",
      "26 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "272.43243408203125\n",
      "0.0\n",
      "Updating fitness with value 0.0337758931012423\n",
      "25 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "328.4440002441406\n",
      "0.0\n",
      "Updating fitness with value 0.0344647469126142\n",
      "24 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "287.6298828125\n",
      "0.0\n",
      "Updating fitness with value 0.04413795308838736\n",
      "23 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "265.6649169921875\n",
      "0.0\n",
      "Updating fitness with value 0.03667223633384947\n",
      "22 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "339.56744384765625\n",
      "0.0\n",
      "Updating fitness with value 0.036184910110370574\n",
      "21 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "245.86593627929688\n",
      "0.0\n",
      "Updating fitness with value 0.1254587190855102\n",
      "20 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "632.519775390625\n",
      "0.0\n",
      "Updating fitness with value 0.046664874843256425\n",
      "19 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "538.89990234375\n",
      "0.0\n",
      "Updating fitness with value 0.13358640944135725\n",
      "18 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "478.32470703125\n",
      "0.0\n",
      "Updating fitness with value 0.041967227741303355\n",
      "17 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "348.2115173339844\n",
      "0.0\n",
      "Updating fitness with value 0.22369583324077588\n",
      "16 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "403.0967712402344\n",
      "0.0\n",
      "Updating fitness with value 0.05009337496574723\n",
      "15 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "512.5979614257812\n",
      "0.0\n",
      "Updating fitness with value 1.1509462379407203\n",
      "14 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "294.916015625\n",
      "0.0\n",
      "Updating fitness with value 0.035305840749962285\n",
      "13 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "135.43238830566406\n",
      "0.0\n",
      "Updating fitness with value 0.04612151288566899\n",
      "12 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "107.07164764404297\n",
      "0.0\n",
      "Updating fitness with value 0.038298365892221735\n",
      "11 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "52.2022819519043\n",
      "0.0\n",
      "Updating fitness with value 0.033727670963039295\n",
      "10 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "24.901853561401367\n",
      "0.0\n",
      "Updating fitness with value 0.03622037478479248\n",
      "9 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "18.19065284729004\n",
      "0.0\n",
      "Updating fitness with value 0.03392182488350351\n",
      "8 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "92.91429138183594\n",
      "0.0\n",
      "Updating fitness with value 0.03729964017029988\n",
      "7 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "99.33452606201172\n",
      "0.0\n",
      "Updating fitness with value 0.03410549786587162\n",
      "6 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "142.9852294921875\n",
      "0.0\n",
      "Updating fitness with value 0.03851996546546801\n",
      "5 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "140.25601196289062\n",
      "0.0\n",
      "Updating fitness with value 0.036765206349835065\n",
      "4 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "33.8170166015625\n",
      "0.0\n",
      "Updating fitness with value 0.03385737172000403\n",
      "3 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "45.04209899902344\n",
      "0.0\n",
      "Updating fitness with value 0.037872894060002764\n",
      "2 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "37.016639709472656\n",
      "0.0\n",
      "Updating fitness with value 0.03415770605610786\n",
      "1 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "20.262407302856445\n",
      "0.0\n",
      "Updating fitness with value 0.034657252342772636\n",
      "0 remaining budget and 0 running jobs\n"
     ]
    }
   ],
   "source": [
    "from adalgorithm import lorahub_aggregation\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "base_lora = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "weights, lorahub_model = lorahub_aggregation(base_lora, lora_adaptors, data[\"valid\"], tokenizer, batch_size = 5, sample_size = 5, seed = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                 | 0/11 [00:00<?, ?it/s]E:\\Anaconda\\envs\\NLP\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2411: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:09<00:00,  1.21it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:23<00:00,  2.10s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:26<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC of client's model: 94.25287356321839, ACC of average aggregated model: 90.80459770114942, ACC of lorahub model: 94.25287356321839, ACC of no noise model: 91.95402298850574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from adalgorithm import average_aggregation\n",
    "from utils import evaluation\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "base_lora = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "avg_model = average_aggregation(base_lora,lora_adaptors)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "base_lora = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "no_noise_model = average_aggregation(base_lora,lora_adaptors[3:])\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "client_model = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "# task_perf_avg, example_predictions = evaluation(data,avg_model,tokenizer, task, batch_size=8)\n",
    "# task_perf_client, example_predictions_error = evaluation(data,client_model,tokenizer, task, batch_size=8)\n",
    "# task_perf_lorahub, example_predictions_error = evaluation(data,lorahub_model,tokenizer, task, batch_size=8)\n",
    "# task_perf_no_noise, example_predictions_error = evaluation(data,no_noise_model,tokenizer, task, batch_size=8)\n",
    "task_perf_avg, example_predictions = evaluation(data,avg_model,tokenizer, batch_size=8)\n",
    "task_perf_client, example_predictions_error = evaluation(data,client_model,tokenizer, batch_size=8)\n",
    "task_perf_lorahub, example_predictions_error = evaluation(data,lorahub_model,tokenizer, batch_size=8)\n",
    "task_perf_no_noise, example_predictions_error = evaluation(data,no_noise_model,tokenizer, batch_size=8)\n",
    "print(f\"ACC of client's model: {task_perf_client}, ACC of average aggregated model: {task_perf_avg}, ACC of lorahub model: {task_perf_lorahub}, ACC of no noise model: {task_perf_no_noise}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [1. 2. 3. 4. 5.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.zeros((5,5))\n",
    "a[1] = [1,2,3,4,5]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(type(task_perf_client))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        # 定义10个可学习的参数\n",
    "        self.weights = nn.Parameter(torch.rand(10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 将每个参数乘以输入矩阵的对应列，然后对列求和，得到10x1的向量\n",
    "        return torch.matmul(x, self.weights.view(-1, 1))\n",
    "\n",
    "model = Model()\n",
    "optimizer = optim.Adam([model.weights], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1547965237.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    task_perf =\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "training_steps = 200\n",
    "for i in tqdm(range(training_steps)):\n",
    "    optimizer.zero_grad()\n",
    "    aggregated_weights = model(weights)\n",
    "    ########\n",
    "    # 合并成一个lora\n",
    "    # loss = evaludation\n",
    "    weighted_model = weighted_aggregation(base_lora, lora_adaptors, aggregated_weights)\n",
    "    task_perf, exmaple_predictions_error = evaluation(data, weighted_model, tokenizer, task, batch_size=8)\n",
    "    task_perf = \n",
    "\n",
    "    ########\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        print(loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

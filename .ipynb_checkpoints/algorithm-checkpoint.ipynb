{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from peft import PeftModel\n",
    "from datasets import DatasetDict, load_dataset\n",
    "from utils import set_seed, k_split\n",
    "from tqdm import trange\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'sst2'\n",
    "data_name = 'glue' if task in ['mnli','qnli','sst2','qqp'] else 'bigbench'\n",
    "seed = 42\n",
    "num_clients = 10\n",
    "num_error_clients = 3\n",
    "number = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'google/flan-t5-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "set_seed(seed)\n",
    "if data_name == 'bigbench':\n",
    "    dataset = load_dataset(\"tasksource/bigbench\", task).shuffle(seed=seed)\n",
    "    dataset = dataset.rename_columns({'inputs':'source','targets':'target'})\n",
    "else:\n",
    "    dataset = load_dataset(\"JsSparkYyx/NLP524\", task).shuffle(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5TokenizerFast(name_or_path='google/flan-t5-base', vocab_size=32100, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "def k_split_(num_clients,num_error_clients,dataset):\n",
    "    data = []\n",
    "    for i in range(num_clients):\n",
    "        subdata = dataset.shard(num_clients,i)\n",
    "        target = subdata['target']\n",
    "        source = subdata['source']\n",
    "        if i < num_error_clients:\n",
    "            random.shuffle(target)\n",
    "        subdata = Dataset.from_dict({'source':source, 'target':target})\n",
    "        data.append(subdata)\n",
    "    return data\n",
    "\n",
    "train_ds = k_split_(num_clients,num_error_clients,dataset['train'])\n",
    "if data_name == 'glue':\n",
    "    valid_ds = k_split_(num_clients,num_error_clients,dataset['valid'])\n",
    "else:\n",
    "    valid_ds = k_split_(num_clients,num_error_clients,dataset['validation'])\n",
    "dataset = DatasetDict({'train':train_ds[number],'valid':valid_ds[number]})\n",
    "def tokenize_function(examples):\n",
    "    # max_length=None => use the model max length (it's actually the default)\n",
    "    model_inputs = tokenizer(examples['source'], truncation=True, max_length=None,padding=True,return_tensors='pt')\n",
    "    if data_name == 'glue':\n",
    "        model_inputs['labels'] = tokenizer(examples['target'], truncation=True, max_length=None,padding=True,return_tensors='pt')[\"input_ids\"]\n",
    "    else:\n",
    "        model_inputs['labels'] = tokenizer([_[0] for _ in examples['target']], truncation=True, max_length=None,padding=True,return_tensors='pt')[\"input_ids\"]\n",
    "    return model_inputs\n",
    "ds = (train_ds, valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive_data(ds,number):\n",
    "    (train_ds, valid_ds) = ds\n",
    "    return DatasetDict({'train':train_ds[number],'valid':valid_ds[number]})\n",
    "\n",
    "def accuracy_score(outputs, ground_truths):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for output, truth in zip(outputs, ground_truths):\n",
    "        if data_name == \"bigbench\":\n",
    "            truth = truth[0]\n",
    "        if output.strip().lower().replace(\".\", \"\") == truth.strip().lower().replace(\".\", \"\"):\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return correct / total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = retrive_data(ds,number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(data, model, tokenizer, batch_size = 128):\n",
    "    example_predictions = []\n",
    "    eval_set = \"valid\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in trange(0, len(data[eval_set][\"source\"]), batch_size):\n",
    "            inputs = tokenizer(\n",
    "                    data[eval_set][\"source\"][i : i + batch_size],\n",
    "                    max_length=2048,\n",
    "                    return_tensors=\"pt\",\n",
    "                    padding=True,\n",
    "                ).to(device)\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"], max_new_tokens=256\n",
    "            )\n",
    "            outputs = tokenizer.batch_decode(\n",
    "                outputs.to(\"cpu\"), skip_special_tokens=True\n",
    "            )\n",
    "            example_predictions.extend(outputs)\n",
    "\n",
    "    task_perf = accuracy_score(example_predictions, data[eval_set][\"target\"])\n",
    "    return task_perf, example_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "# lora_model = PeftModel.from_pretrained(model_1,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "# model_2 = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "# error_model = PeftModel.from_pretrained(model_2,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-0')\n",
    "# task_perf, example_predictions = evaluation(data,lora_model,tokenizer, batch_size=8)\n",
    "# task_perf_error, example_predictions_error = evaluation(data,error_model,tokenizer, batch_size=8)\n",
    "# print(f\"ACC of error model: {task_perf_error}, ACC of lora model: {task_perf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model_state_dict\n",
    "lora_adaptors = []\n",
    "for i in range(num_clients):\n",
    "    base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "    lora_model = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{i}')\n",
    "    lora_adaptors.append(get_peft_model_state_dict(lora_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2d2c0d13db4155b5450e60182f62bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Begin to perform gradient-free optimization ...\n",
      "Launching 1 jobs with new suggestions\n",
      "2205.1943359375\n",
      "0.0\n",
      "Updating fitness with value 2205.300279355049\n",
      "39 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "1122.6883544921875\n",
      "0.0\n",
      "Updating fitness with value 1122.761525347233\n",
      "38 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "926.9755249023438\n",
      "0.0\n",
      "Updating fitness with value 927.055372326374\n",
      "37 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "2475.89013671875\n",
      "0.0\n",
      "Updating fitness with value 2475.976275832653\n",
      "36 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "1179.2130126953125\n",
      "0.0\n",
      "Updating fitness with value 1179.2856671404838\n",
      "35 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "542.4270629882812\n",
      "0.0\n",
      "Updating fitness with value 542.4990968418122\n",
      "34 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "1436.620361328125\n",
      "0.0\n",
      "Updating fitness with value 1436.6810722386838\n",
      "33 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "205.25233459472656\n",
      "0.0\n",
      "Updating fitness with value 205.31949288010597\n",
      "32 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "449.2734069824219\n",
      "0.0\n",
      "Updating fitness with value 451.23223876953125\n",
      "31 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "376.595947265625\n",
      "0.0\n",
      "Updating fitness with value 378.2836965560913\n",
      "30 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "208.94744873046875\n",
      "0.0\n",
      "Updating fitness with value 210.79148635864257\n",
      "29 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "1193.2052001953125\n",
      "0.0\n",
      "Updating fitness with value 1193.2872125609663\n",
      "28 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "129.94979858398438\n",
      "0.0\n",
      "Updating fitness with value 130.0092976144276\n",
      "27 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "292.95770263671875\n",
      "0.0\n",
      "Updating fitness with value 293.0221182699614\n",
      "26 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "1652.3974609375\n",
      "0.0\n",
      "Updating fitness with value 1652.4696847322432\n",
      "25 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "430.5251770019531\n",
      "0.0\n",
      "Updating fitness with value 430.592845586944\n",
      "24 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "1454.634033203125\n",
      "0.0\n",
      "Updating fitness with value 1454.6849838471205\n",
      "23 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "453.0135803222656\n",
      "0.0\n",
      "Updating fitness with value 453.07568426224003\n",
      "22 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "1733.3707275390625\n",
      "0.0\n",
      "Updating fitness with value 1733.4357413890189\n",
      "21 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "1363.2882080078125\n",
      "0.0\n",
      "Updating fitness with value 1363.351501068365\n",
      "20 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "633.9122924804688\n",
      "0.0\n",
      "Updating fitness with value 633.970357463363\n",
      "19 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "372.3276062011719\n",
      "0.0\n",
      "Updating fitness with value 372.3920348605195\n",
      "18 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "732.785888671875\n",
      "0.0\n",
      "Updating fitness with value 732.8522482423874\n",
      "17 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "860.9923095703125\n",
      "0.0\n",
      "Updating fitness with value 861.1621788196352\n",
      "16 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "1361.7864990234375\n",
      "0.0\n",
      "Updating fitness with value 1361.8500311544533\n",
      "15 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "145.19952392578125\n",
      "0.0\n",
      "Updating fitness with value 145.25558191595468\n",
      "14 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "71.66419219970703\n",
      "0.0\n",
      "Updating fitness with value 71.7232014831279\n",
      "13 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "203.97523498535156\n",
      "0.0\n",
      "Updating fitness with value 204.03336471635885\n",
      "12 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "474.3149108886719\n",
      "0.0\n",
      "Updating fitness with value 474.3737649342884\n",
      "11 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "494.1429138183594\n",
      "0.0\n",
      "Updating fitness with value 494.20223191996047\n",
      "10 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "264.6608581542969\n",
      "0.0\n",
      "Updating fitness with value 264.72036162695343\n",
      "9 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "123.64115142822266\n",
      "0.0\n",
      "Updating fitness with value 123.70012978334593\n",
      "8 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "291.7857360839844\n",
      "0.0\n",
      "Updating fitness with value 291.8464880464337\n",
      "7 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "792.5677490234375\n",
      "0.0\n",
      "Updating fitness with value 792.6264959871891\n",
      "6 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "335.00006103515625\n",
      "0.0\n",
      "Updating fitness with value 335.05836706642924\n",
      "5 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "130.80328369140625\n",
      "0.0\n",
      "Updating fitness with value 130.8620701392113\n",
      "4 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "12.791792869567871\n",
      "0.0\n",
      "Updating fitness with value 12.850784779177161\n",
      "3 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "27.04271125793457\n",
      "0.0\n",
      "Updating fitness with value 27.101377660469318\n",
      "2 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "277.7320251464844\n",
      "0.0\n",
      "Updating fitness with value 277.7910051143371\n",
      "1 remaining budget and 0 running jobs\n",
      "Launching 1 jobs with new suggestions\n",
      "278.49658203125\n",
      "0.0\n",
      "Updating fitness with value 278.5565490103821\n",
      "0 remaining budget and 0 running jobs\n"
     ]
    }
   ],
   "source": [
    "from algorithm import lorahub_aggregation\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "base_lora = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "weights, lorahub_model = lorahub_aggregation(base_lora, lora_adaptors, data[\"valid\"], tokenizer, batch_size = 5, sample_size = 5, seed = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                 | 0/11 [00:00<?, ?it/s]E:\\Anaconda\\envs\\NLP\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2411: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:18<00:00,  1.67s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:28<00:00,  2.57s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:25<00:00,  2.32s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:24<00:00,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC of client's model: 94.25287356321839, ACC of average aggregated model: 90.80459770114942, ACC of lorahub model: 91.95402298850574, ACC of no noise model: 91.95402298850574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from algorithm import average_aggregation\n",
    "from utils import evaluation\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "base_lora = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "avg_model = average_aggregation(base_lora,lora_adaptors)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "base_lora = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "no_noise_model = average_aggregation(base_lora,lora_adaptors[3:])\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path, return_dict=True)\n",
    "client_model = PeftModel.from_pretrained(base_model,f'JsSparkYyx/flan-t5-base-finetuned-lora-{task}-{number}')\n",
    "# task_perf_avg, example_predictions = evaluation(data,avg_model,tokenizer, task, batch_size=8)\n",
    "# task_perf_client, example_predictions_error = evaluation(data,client_model,tokenizer, task, batch_size=8)\n",
    "# task_perf_lorahub, example_predictions_error = evaluation(data,lorahub_model,tokenizer, task, batch_size=8)\n",
    "# task_perf_no_noise, example_predictions_error = evaluation(data,no_noise_model,tokenizer, task, batch_size=8)\n",
    "task_perf_avg, example_predictions = evaluation(data,avg_model,tokenizer, batch_size=8)\n",
    "task_perf_client, example_predictions_error = evaluation(data,client_model,tokenizer, batch_size=8)\n",
    "task_perf_lorahub, example_predictions_error = evaluation(data,lorahub_model,tokenizer, batch_size=8)\n",
    "task_perf_no_noise, example_predictions_error = evaluation(data,no_noise_model,tokenizer, batch_size=8)\n",
    "print(f\"ACC of client's model: {task_perf_client}, ACC of average aggregated model: {task_perf_avg}, ACC of lorahub model: {task_perf_lorahub}, ACC of no noise model: {task_perf_no_noise}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [1. 2. 3. 4. 5.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.zeros((5,5))\n",
    "a[1] = [1,2,3,4,5]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(type(task_perf_client))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        # 定义10个可学习的参数\n",
    "        self.weights = nn.Parameter(torch.rand(10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 将每个参数乘以输入矩阵的对应列，然后对列求和，得到10x1的向量\n",
    "        return torch.matmul(x, self.weights.view(-1, 1))\n",
    "\n",
    "model = Model()\n",
    "optimizer = optim.Adam([model.weights], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1547965237.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    task_perf =\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "training_steps = 200\n",
    "for i in tqdm(range(training_steps)):\n",
    "    optimizer.zero_grad()\n",
    "    aggregated_weights = model(weights)\n",
    "    ########\n",
    "    # 合并成一个lora\n",
    "    # loss = evaludation\n",
    "    weighted_model = weighted_aggregation(base_lora, lora_adaptors, aggregated_weights)\n",
    "    task_perf, exmaple_predictions_error = evaluation(data, weighted_model, tokenizer, task, batch_size=8)\n",
    "    task_perf = \n",
    "\n",
    "    ########\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        print(loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

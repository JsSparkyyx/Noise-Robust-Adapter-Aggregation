{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "GLUE_TASKS = [\"cola\", \"mnli\", \"mnli-mm\", \"mrpc\", \"qnli\", \"qqp\", \"rte\", \"sst2\", \"stsb\", \"wnli\"]\n",
    "task = \"mnli\"\n",
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mnli-mm\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "num_labels = 3 if task.startswith(\"mnli\") else 1 if task==\"stsb\" else 2\n",
    "sentence1_key, sentence2_key = task_to_keys[task]\n",
    "model_name_or_path = \"google/flan-t5-base\"\n",
    "num_epochs = 2\n",
    "lr = 1e-3\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478e98cd3ef74eea9935efab86fbdaf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/313M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008dea3463df428cad0150e4d2f88e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c2fc9e32524f0da573ee7b8953a929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72a52e952df49bebf3ec770bd52cfe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0e0eb6d2344cb1ba1bae5bbaa763f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_matched split:   0%|          | 0/9796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba5bf9dacfa47a99efb21558424a9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_mismatched split:   0%|          | 0/9847 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"glue\", task)\n",
    "metric = evaluate.load(\"glue\", task)\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c2a23497974b879ca6938c184fb221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/392702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6392eea6813e43269d31209eb7e8a180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075f5576618e4799960899013c5f2f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03f0e6809504e709369965825056f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad2ccd1cf814485813eaa1373bb5592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9847 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at google/flan-t5-base and are newly initialized: ['classification_head.out_proj.weight', 'classification_head.out_proj.bias', 'classification_head.dense.weight', 'classification_head.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,538,944 || all params: 227,035,395 || trainable%: 1.5587631170901788\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # max_length=None => use the model max length (it's actually the default)\n",
    "    if sentence2_key is None:\n",
    "        outputs = tokenizer(examples[sentence1_key], truncation=True, max_length=None)\n",
    "    else:\n",
    "        outputs = tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=True, max_length=None)\n",
    "    return outputs\n",
    "\n",
    "if sentence2_key!=None:\n",
    "    tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"idx\", sentence1_key, sentence2_key])\n",
    "else:\n",
    "    tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"idx\", sentence1_key])\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    # target_modules=[\"query\",\"key\",\"value\"],\n",
    "    target_modules=[\"q\",\"k\",\"v\",\"o\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"classifier\"],\n",
    ")\n",
    "\n",
    "model_name = model_name_or_path.split(\"/\")[-1]\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, return_dict=True, num_labels=num_labels)\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-lora-{task}\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\WashU\\NLP524Final\\test.ipynb 单元格 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/WashU/NLP524Final/test.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/WashU/NLP524Final/test.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/WashU/NLP524Final/test.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/WashU/NLP524Final/test.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     train_dataset\u001b[39m=\u001b[39mtokenized_datasets[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Code/WashU/NLP524Final/test.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     eval_dataset\u001b[39m=\u001b[39mtokenized_datasets[\u001b[39m\"\u001b[39;49m\u001b[39mvalidation\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/WashU/NLP524Final/test.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     tokenizer\u001b[39m=\u001b[39mtokenizer,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/WashU/NLP524Final/test.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     data_collator\u001b[39m=\u001b[39mdata_collator,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/WashU/NLP524Final/test.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/WashU/NLP524Final/test.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/WashU/NLP524Final/test.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\LLM\\lib\\site-packages\\datasets\\dataset_dict.py:59\u001b[0m, in \u001b[0;36mDatasetDict.__getitem__\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, k) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dataset:\n\u001b[0;32m     58\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(k, (\u001b[39mstr\u001b[39m, NamedSplit)) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 59\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(k)\n\u001b[0;32m     60\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m         available_suggested_splits \u001b[39m=\u001b[39m [\n\u001b[0;32m     62\u001b[0m             split \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m (Split\u001b[39m.\u001b[39mTRAIN, Split\u001b[39m.\u001b[39mTEST, Split\u001b[39m.\u001b[39mVALIDATION) \u001b[39mif\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m     63\u001b[0m         ]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'validation'"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't find 'adapter_config.json' at 'flan-t5-base-finetuned-lora-cola'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\LLM\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:261\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 261\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[0;32m    262\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\LLM\\lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/flan-t5-base-finetuned-lora-cola/resolve/main/adapter_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\LLM\\lib\\site-packages\\peft\\config.py:105\u001b[0m, in \u001b[0;36mPeftConfigMixin.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, subfolder, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     config_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[0;32m    106\u001b[0m         pretrained_model_name_or_path, CONFIG_NAME, subfolder\u001b[39m=\u001b[39msubfolder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhf_hub_download_kwargs\n\u001b[0;32m    107\u001b[0m     )\n\u001b[0;32m    108\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\LLM\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\LLM\\lib\\site-packages\\huggingface_hub\\file_download.py:1346\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, endpoint, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[0;32m   1344\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[0;32m   1345\u001b[0m     \u001b[39m# Repo not found => let's raise the actual error\u001b[39;00m\n\u001b[1;32m-> 1346\u001b[0m     \u001b[39mraise\u001b[39;00m head_call_error\n\u001b[0;32m   1347\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1348\u001b[0m     \u001b[39m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\LLM\\lib\\site-packages\\huggingface_hub\\file_download.py:1232\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, endpoint, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1232\u001b[0m     metadata \u001b[39m=\u001b[39m get_hf_file_metadata(\n\u001b[0;32m   1233\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m   1234\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m   1235\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   1236\u001b[0m         timeout\u001b[39m=\u001b[39;49metag_timeout,\n\u001b[0;32m   1237\u001b[0m     )\n\u001b[0;32m   1238\u001b[0m \u001b[39mexcept\u001b[39;00m EntryNotFoundError \u001b[39mas\u001b[39;00m http_error:\n\u001b[0;32m   1239\u001b[0m     \u001b[39m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\LLM\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\LLM\\lib\\site-packages\\huggingface_hub\\file_download.py:1608\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[0;32m   1599\u001b[0m r \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[0;32m   1600\u001b[0m     method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHEAD\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1601\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1606\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[0;32m   1607\u001b[0m )\n\u001b[1;32m-> 1608\u001b[0m hf_raise_for_status(r)\n\u001b[0;32m   1610\u001b[0m \u001b[39m# Return\u001b[39;00m\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\LLM\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:293\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    285\u001b[0m     message \u001b[39m=\u001b[39m (\n\u001b[0;32m    286\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Client Error.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m make sure you are authenticated.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m     )\n\u001b[1;32m--> 293\u001b[0m     \u001b[39mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[39melif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m400\u001b[39m:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-655565b8-774cb3ec421eef9212cf5fed;dd92e450-1347-47e1-b2e8-0cb057d68d7d)\n\nRepository Not Found for url: https://huggingface.co/flan-t5-base-finetuned-lora-cola/resolve/main/adapter_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\WashU\\NLP524Final\\test.ipynb 单元格 5\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/WashU/NLP524Final/test.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoModelForSequenceClassification, AutoTokenizer\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/WashU/NLP524Final/test.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m peft_model_id \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m-finetuned-lora-\u001b[39m\u001b[39m{\u001b[39;00mtask\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Code/WashU/NLP524Final/test.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m config \u001b[39m=\u001b[39m PeftConfig\u001b[39m.\u001b[39;49mfrom_pretrained(peft_model_id)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/WashU/NLP524Final/test.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m inference_model \u001b[39m=\u001b[39m AutoModelForSequenceClassification\u001b[39m.\u001b[39mfrom_pretrained(config\u001b[39m.\u001b[39mbase_model_name_or_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/WashU/NLP524Final/test.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(config\u001b[39m.\u001b[39mbase_model_name_or_path)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\LLM\\lib\\site-packages\\peft\\config.py:109\u001b[0m, in \u001b[0;36mPeftConfigMixin.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, subfolder, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m         config_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[0;32m    106\u001b[0m             pretrained_model_name_or_path, CONFIG_NAME, subfolder\u001b[39m=\u001b[39msubfolder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhf_hub_download_kwargs\n\u001b[0;32m    107\u001b[0m         )\n\u001b[0;32m    108\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m--> 109\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mCONFIG_NAME\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m at \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    111\u001b[0m loaded_attributes \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_json_file(config_file)\n\u001b[0;32m    113\u001b[0m \u001b[39m# TODO: this hack is needed to fix the following issue (on commit 702f937):\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[39m# if someone saves a default config and loads it back with `PeftConfig` class it yields to\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39m# not loading the correct config class.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39m# print(peft_config)\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[39m# >>> PeftConfig(peft_type='ADALORA', auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=None, inference_mode=False)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Can't find 'adapter_config.json' at 'flan-t5-base-finetuned-lora-cola'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "peft_model_id = f\"{model_name}-finetuned-lora-{task}\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "inference_model = AutoModelForSequenceClassification.from_pretrained(config.base_model_name_or_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "model = PeftModel.from_pretrained(inference_model, peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"not equivalent\", \"equivalent\"]\n",
    "\n",
    "sentence1 = \"I am a student\"\n",
    "\n",
    "inputs = tokenizer(sentence1, truncation=True, padding=\"longest\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1007, -0.2035]])\n",
      "not equivalent: 58%\n",
      "equivalent: 42%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs).logits\n",
    "    print(outputs)\n",
    "\n",
    "paraphrased_text = torch.softmax(outputs, dim=1).tolist()[0]\n",
    "for i in range(len(classes)):\n",
    "    print(f\"{classes[i]}: {int(round(paraphrased_text[i] * 100))}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>single</th>\n",
       "      <th>avg</th>\n",
       "      <th>cv</th>\n",
       "      <th>lorahub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.165824</td>\n",
       "      <td>84.809512</td>\n",
       "      <td>84.962232</td>\n",
       "      <td>85.093171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.072214</td>\n",
       "      <td>91.705913</td>\n",
       "      <td>92.150706</td>\n",
       "      <td>91.889063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.417077</td>\n",
       "      <td>92.775041</td>\n",
       "      <td>93.267652</td>\n",
       "      <td>94.252874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86.876789</td>\n",
       "      <td>85.735486</td>\n",
       "      <td>85.742553</td>\n",
       "      <td>81.9017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.374152</td>\n",
       "      <td>26.404121</td>\n",
       "      <td>27.471877</td>\n",
       "      <td>28.427369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.764818</td>\n",
       "      <td>0.273149</td>\n",
       "      <td>0.409724</td>\n",
       "      <td>0.355094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24.149248</td>\n",
       "      <td>15.186178</td>\n",
       "      <td>20.889161</td>\n",
       "      <td>18.617808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.087108</td>\n",
       "      <td>4.947735</td>\n",
       "      <td>5.017422</td>\n",
       "      <td>4.390244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18.857143</td>\n",
       "      <td>19.047619</td>\n",
       "      <td>21.714286</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48.640486</td>\n",
       "      <td>46.764973</td>\n",
       "      <td>47.958401</td>\n",
       "      <td>47.362295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      single        avg         cv    lorahub\n",
       "0  85.165824  84.809512  84.962232  85.093171\n",
       "1  92.072214  91.705913  92.150706  91.889063\n",
       "2  94.417077  92.775041  93.267652  94.252874\n",
       "3  86.876789  85.735486  85.742553    81.9017\n",
       "4  30.374152  26.404121  27.471877  28.427369\n",
       "5   0.764818   0.273149   0.409724   0.355094\n",
       "6  24.149248  15.186178  20.889161  18.617808\n",
       "7   5.087108   4.947735   5.017422   4.390244\n",
       "8  18.857143  19.047619  21.714286  21.333333\n",
       "9  48.640486  46.764973  47.958401  47.362295"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "tasks = ['mnli','qnli','sst2','qqp','elementary_math_qa','cryptonite','intersect_geometry','list_functions','tracking_shuffled_objects']\n",
    "methods = ['single','cv','lorahub','avg']\n",
    "table = pd.DataFrame([],columns=['single','avg','cv','lorahub'])\n",
    "for idx,task in enumerate(tasks):\n",
    "    for method in methods:\n",
    "        data_name = 'glue' if task in ['mnli','qnli','sst2','qqp'] else 'bigbench'\n",
    "        path = f\"../results/{data_name}/{task}_{method}.csv\"\n",
    "        result = np.loadtxt(path,delimiter=',')\n",
    "        if method == 'avg':\n",
    "            table.loc[idx,method] = np.mean(result[3:10])\n",
    "        else:\n",
    "            table.loc[idx,method] = np.mean(result[3:10,3:10].diagonal())\n",
    "table.loc[9] = table.mean(axis=0)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lorahub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.119879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.074526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.030892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.048567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.04723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lorahub\n",
       "0   0.05565\n",
       "1  0.001066\n",
       "2  0.029939\n",
       "3  0.023008\n",
       "4  0.041546\n",
       "5  0.119879\n",
       "6  0.074526\n",
       "7  0.030892\n",
       "8  0.048567\n",
       "9   0.04723"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "tasks = ['mnli','qnli','sst2','qqp','elementary_math_qa','cryptonite','intersect_geometry','list_functions','tracking_shuffled_objects']\n",
    "methods = ['lorahub']\n",
    "table = pd.DataFrame([],columns=['lorahub'])\n",
    "for idx,task in enumerate(tasks):\n",
    "    for method in methods:\n",
    "        data_name = 'glue' if task in ['mnli','qnli','sst2','qqp'] else 'bigbench'\n",
    "        path = f\"../results/{data_name}/{task}_{method}_weights.csv\"\n",
    "        result = np.loadtxt(path,delimiter=',')[3:]\n",
    "        table.loc[idx,method] = np.mean(np.absolute(result[:10,:3]).sum(axis=1)/10)\n",
    "table.loc[9] = table.mean(axis=0)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 0. 1. 0. 1. 0. 1. 2. 0. 2. 0. 2. 0.]\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [2 0]\n",
      " [2 1]\n",
      " [3 0]\n",
      " [3 1]\n",
      " [3 2]\n",
      " [4 0]\n",
      " [4 1]\n",
      " [5 0]\n",
      " [5 1]\n",
      " [6 0]]\n",
      "[2. 0. 2. 1. 2. 1. 2. 1. 1. 2. 1. 2.]\n",
      "[[0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [2 0]\n",
      " [2 1]\n",
      " [3 0]\n",
      " [3 1]\n",
      " [4 0]\n",
      " [5 0]\n",
      " [5 1]\n",
      " [6 0]\n",
      " [6 1]]\n",
      "[0. 0. 1. 2. 0. 1. 1. 2. 0. 0. 1. 2. 0. 2.]\n",
      "[[0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [2 0]\n",
      " [2 1]\n",
      " [3 0]\n",
      " [3 1]\n",
      " [4 0]\n",
      " [5 0]\n",
      " [5 1]\n",
      " [5 2]\n",
      " [6 0]\n",
      " [6 1]]\n",
      "[0. 1. 2. 0. 0. 1. 2. 0. 1. 2. 0. 1. 1. 0. 1.]\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 0]\n",
      " [2 0]\n",
      " [2 1]\n",
      " [2 2]\n",
      " [3 0]\n",
      " [3 1]\n",
      " [3 2]\n",
      " [4 0]\n",
      " [4 1]\n",
      " [5 0]\n",
      " [6 0]\n",
      " [6 1]]\n",
      "[0. 2. 1. 2. 0. 1. 0. 0. 2. 1. 2.]\n",
      "[[0 0]\n",
      " [1 0]\n",
      " [2 0]\n",
      " [2 1]\n",
      " [3 0]\n",
      " [3 1]\n",
      " [4 0]\n",
      " [5 0]\n",
      " [5 1]\n",
      " [6 0]\n",
      " [6 1]]\n",
      "[0. 1. 2. 1. 0. 1. 2. 1. 2. 0. 2. 0. 1.]\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 0]\n",
      " [2 0]\n",
      " [2 1]\n",
      " [2 2]\n",
      " [4 0]\n",
      " [4 1]\n",
      " [5 0]\n",
      " [5 1]\n",
      " [6 0]\n",
      " [6 1]]\n",
      "[0. 1. 0. 1. 0. 0. 2.]\n",
      "[[0 0]\n",
      " [2 0]\n",
      " [3 0]\n",
      " [3 1]\n",
      " [4 0]\n",
      " [5 0]\n",
      " [6 0]]\n",
      "[0. 1. 2. 0. 2. 1. 2. 1. 2. 0. 1. 2. 0. 1. 0. 2.]\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [2 0]\n",
      " [2 1]\n",
      " [3 0]\n",
      " [3 1]\n",
      " [4 0]\n",
      " [4 1]\n",
      " [4 2]\n",
      " [5 0]\n",
      " [5 1]\n",
      " [6 0]\n",
      " [6 1]]\n",
      "[0. 1. 0. 1. 2. 1. 2. 0. 1. 2. 1. 0. 1. 2. 0. 1. 2.]\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 2]\n",
      " [2 0]\n",
      " [2 1]\n",
      " [3 0]\n",
      " [3 1]\n",
      " [3 2]\n",
      " [4 0]\n",
      " [5 0]\n",
      " [5 1]\n",
      " [5 2]\n",
      " [6 0]\n",
      " [6 1]\n",
      " [6 2]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cv\n",
       "9  NaN"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "tasks = ['mnli','qnli','sst2','qqp','elementary_math_qa','cryptonite','intersect_geometry','list_functions','tracking_shuffled_objects']\n",
    "methods = ['cv']\n",
    "table = pd.DataFrame([],columns=['cv'])\n",
    "for idx,task in enumerate(tasks):\n",
    "    for method in methods:\n",
    "        data_name = 'glue' if task in ['mnli','qnli','sst2','qqp'] else 'bigbench'\n",
    "        path = f\"../results/{data_name}/{task}_{method}_weights.csv\"\n",
    "        result = np.loadtxt(path,delimiter=',')[3:]\n",
    "        print(result[result <= 2])\n",
    "        print(np.argwhere(result <= 2))\n",
    "        # table.loc[idx,method] = np.mean(np.absolute(result[:10,:3]).mean(axis=1))\n",
    "table.loc[9] = table.mean(axis=0)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
